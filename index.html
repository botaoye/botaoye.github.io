<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Botao Ye</title>

    <meta name="author" content="Botao Ye">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="media/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Botao Ye
                </p>
                <p>I am a PhD student at <a href="https://ethz.ch/en.html">ETH Zurich</a>, supervised by Prof. <a href="https://people.inf.ethz.ch/marc.pollefeys/">Marc Pollefeys</a> and Prof. <a href="https://rpg.ifi.uzh.ch/people_scaramuzza.html">Davide Scaramuzza</a>. I am also a Doctoral Fellow at <a href="https://ai.ethz.ch/">ETH AI Center</a>.
                </p>
                <p>
                  I completed my master's degree at the <a href="https://english.ucas.ac.cn/">University of Chinese Academy of Sciences</a>, where I was lucky enough to be supervised by Prof. <a href="https://scholar.google.com/citations?user=LX6MnNsAAAAJ&hl=en">Hong Chang</a>.
                  I was also very fortunate to work with Prof. <a href="https://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>.
                  I obtained my bachelor's degree at <a href="https://www.zju.edu.cn/english/">Zhejiang University</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:botao.ye@inf.ethz.ch">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=BdIyfRgAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/Botao_Ye">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/botaoye/">Github</a>
                </p>
              </td>
              <td style="padding: 10% 2% 10% 2%;width:40%;max-width:40%">
                <img src="media/BotaoYe.jpeg" width="200" alt="photo">
              </td>  
            </tr>
          </tbody></table>

          <!-- Research -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I have broad interests in computer vision, and now mainly working on 3D vision and generative models.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <!-- NoPoSplat -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <video autoplay muted loop width="180">
                  <source src="media/noposplat.mp4"
                          type="video/mp4">
                </video>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2410.24207">
                  <papertitle>NoPoSplat: Surprisingly Simple 3D Gaussian Splats from Sparse Unposed Images
                  </papertitle>
                </a>
                <br>
                <strong>Botao Ye</strong>,
                <a href="https://sifeiliu.net/">Sifei Liu</a>,
                <a href="https://haofeixu.github.io/">Haofei Xu</a>,
                <a href="https://sunshineatnoon.github.io/">Xueting Li</a>,
                <a href="https://people.inf.ethz.ch/marc.pollefeys/">Marc Pollefeys</a>,
                <a href="https://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>,
                <a href="https://pengsongyou.github.io/">Songyou Peng</a>
                <br>
                <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2025 (Oral)
                <br>
                <br>
                <a href="https://noposplat.github.io/">project page</a>
                /
                <a href="https://github.com/cvg/NoPoSplat">code</a> 
                <iframe src="https://ghbtns.com/github-btn.html?user=cvg&repo=NoPoSplat&type=star&count=true&size=small" frameborder="0" scrolling="0" width="100" height="20" title="GitHub"></iframe>
                <p></p>
                <p>
                  A feed-forward model that reconstructs scenes from unposed images, demonstrating superior performance in both novel view synthesis and pose estimation.
                </p>
              </td>
            </tr>

            <!-- DiffuNVS -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='media/diffuNVS.png' width="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2502.18219">
                  <papertitle>Synthesizing Consistent Novel Views via 3D Epipolar Attention without Re-training
                  </papertitle>
                </a>
                <br>
                <strong>Botao Ye</strong>,
                <a href="https://sifeiliu.net/">Sifei Liu</a>,
                <a href="https://sunshineatnoon.github.io/">Xueting Li</a>,
                <a href="https://people.inf.ethz.ch/marc.pollefeys/">Marc Pollefeys</a>,
                <a href="https://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>
                <br>
                <em>International Conference on 3D Vision (<strong>3DV</strong>)</em>, 2025
                <br>
                <a href="#">code</a> 
                <p></p>
                <p>
                  Improving the consistency of diffusion-based multi-view image generation model without retraining using epipolar attention.
                </p>
              </td>
            </tr>
            
            <!-- S3PRecon -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='media/super_plane.png' width="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_Self-Supervised_Super-Plane_for_Neural_3D_Reconstruction_CVPR_2023_paper.pdf">
                  <papertitle>Self-supervised Super-plane for Neural 3D Reconstruction
                  </papertitle>
                </a>
                <br>
                <strong>Botao Ye</strong>,
                <a href="https://sifeiliu.net/">Sifei Liu</a>,
                <a href="https://sunshineatnoon.github.io/">Xueting Li</a>,
                <a href="https://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>
                <br>
                <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2023
                <br>
                <a href="https://github.com/botaoye/S3PRecon">code</a> 
                <p></p>
                <p>
                  A self-supervised super-plane constraint for neural implicit 3D reconstruction.
                </p>
              </td>
            </tr>

            <!-- OSTrack -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='media/ostrack.png' width="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2203.11991">
                  <papertitle>Joint Feature Learning and Relation Modeling for Tracking: A One-Stream Framework
                  </papertitle>
                </a>
                <br>
                <strong>Botao Ye</strong>,
                <a href="https://scholar.google.com/citations?user=LX6MnNsAAAAJ&hl=en">Hong Chang</a>,
                <a href="https://people.ucas.edu.cn/~bpma?language=en">Bingpeng Ma</a>,
                <a href="https://people.ucas.edu.cn/~sgshan?language=en">Shiguang Shan</a>,
                <a href="https://people.ucas.ac.cn/~xlchen?language=en">Xilin Chen</a>
                <br>
                <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2022
                <br>
                <a href="https://github.com/botaoye/OSTrack">code</a> 
                <iframe src="https://ghbtns.com/github-btn.html?user=botaoye&repo=OSTrack&type=star&count=true&size=small" frameborder="0" scrolling="0" width="100" height="20" title="GitHub"></iframe>
                <p></p>
                <p>
                  An efficeint one-stream framework for visual object tracking.
                </p>
              </td>
            </tr>

            <!-- Mono3D -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='media/mono3d.png' width="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2104.05858">
                  <papertitle>Exploring Geometric Consistency for Monocular 3D Object Detection
                  </papertitle>
                </a>
                <br>
                <a href="https://lianqing11.github.io/">Qing Lian</a>,
                <strong>Botao Ye</strong>,
                <a href="https://scholar.google.co.jp/citations?user=-1scaLMAAAAJ&hl=en">Ruijia Xu</a>,
                <a href="https://sites.google.com/site/wlyao95">Weilong Yao</a>,
                <a href="https://tongzhang-ml.org/">Tong Zhang</a>
                <br>
                <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2022
                <br>
                
                <p></p>
                <p>
                  Exploring geometrically consistent data augmentation methods for monocular 3D object detection.
                </p>
              </td>
            </tr>
        
          </tbody></table>

        <!-- Awards and Honors -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding-top:5px;padding-bottom:5px;padding-left:20px;padding-right:20px;width:100%;vertical-align:middle">
            <h2>Awards</h2>
            <ul>
              <li><a href="https://prints.vicos.si/publications/416">1<sup>st</sup> place in the VOT 2022 real-time bounding box tracking challenge</a>, <a href="https://www.votchallenge.net/vot2022/"> ECCV 2022 VOT Workshop</a></li>
              <li><a href="https://prints.vicos.si/publications/416">1<sup>st</sup> place in the VOT 2022 short-term bounding box tracking challenge</a>, <a href="https://www.votchallenge.net/vot2022/"> ECCV 2022 VOT Workshop</a></li>
            </ul>
          </td>
          </tr>
        </tbody></table>
        
          
        <!-- Academic Services -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding-top:5px;padding-bottom:5px;padding-left:20px;padding-right:20px;width:100%;vertical-align:middle">
            <h2>Academic Services</h2>
            <ul>
              <li>Conference Reviewer: CVPR, ICCV, ECCV, NeurIPS, ICLR, 3DV</li>
              <li>Journal Reviewer: TPAMI, IJCV, TIP</li>
            </ul>
          </td>
          </tr>
        </tbody></table>
          

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
              <br>
              <p align="center">
                <font size="2">template adapted from
                <a href="https://jonbarron.info/"><font size="2" color="lightgray">this awesome website</font></a>
                <br>
              </font>
              </p>
              </td>
            </tr>
            </table>  
            
            
        </td>
      </tr>
    </table>
  </body>
</html>
